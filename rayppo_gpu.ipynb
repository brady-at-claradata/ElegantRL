{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rayppo_gpu.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNK04a3w/NRTueZ80RTsvJy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brady-at-claradata/ElegantRL/blob/master/rayppo_gpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yFLcYjSofcXR",
        "outputId": "a5d966e7-9a32-48b3-c6df-bc88531ce4ff"
      },
      "source": [
        "!pip install ray[all] torch tensortrade stockstats yfinance pandas \n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ray[all]\n",
            "  Downloading ray-1.5.0-cp37-cp37m-manylinux2014_x86_64.whl (51.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 51.5 MB 39 kB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Collecting tensortrade\n",
            "  Downloading tensortrade-1.0.3.tar.gz (32.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.6 MB 23 kB/s \n",
            "\u001b[?25hCollecting stockstats\n",
            "  Downloading stockstats-0.3.2-py2.py3-none-any.whl (13 kB)\n",
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.63.tar.gz (26 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from tensortrade) (1.19.5)\n",
            "Requirement already satisfied: gym>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from tensortrade) (0.17.3)\n",
            "Collecting pyyaml>=5.1.2\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 37.5 MB/s \n",
            "\u001b[?25hCollecting stochastic>=0.6.0\n",
            "  Downloading stochastic-0.6.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tensortrade) (2.5.0)\n",
            "Collecting ipython>=7.12.0\n",
            "  Downloading ipython-7.25.0-py3-none-any.whl (786 kB)\n",
            "\u001b[K     |████████████████████████████████| 786 kB 34.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from tensortrade) (3.2.2)\n",
            "Collecting plotly>=4.5.0\n",
            "  Downloading plotly-5.1.0-py2.py3-none-any.whl (20.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.6 MB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.14.0->tensortrade) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.14.0->tensortrade) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym>=0.14.0->tensortrade) (1.4.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.12.0->tensortrade) (0.2.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.12.0->tensortrade) (57.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from ipython>=7.12.0->tensortrade) (0.1.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.12.0->tensortrade) (0.18.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=7.12.0->tensortrade) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.12.0->tensortrade) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.12.0->tensortrade) (2.6.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.12.0->tensortrade) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.12.0->tensortrade) (5.0.5)\n",
            "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "  Downloading prompt_toolkit-3.0.19-py3-none-any.whl (368 kB)\n",
            "\u001b[K     |████████████████████████████████| 368 kB 40.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.12.0->tensortrade) (0.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.1->tensortrade) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.1->tensortrade) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.1->tensortrade) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=3.1.1->tensortrade) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=7.12.0->tensortrade) (0.7.0)\n",
            "Collecting tenacity>=6.2.0\n",
            "  Downloading tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.12.0->tensortrade) (0.2.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.14.0->tensortrade) (0.16.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tensortrade) (3.3.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tensortrade) (1.34.1)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tensortrade) (1.1.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tensortrade) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tensortrade) (2.5.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tensortrade) (0.4.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tensortrade) (1.6.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tensortrade) (1.12.1)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tensortrade) (1.12)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tensortrade) (3.1.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tensortrade) (2.5.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tensortrade) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tensortrade) (3.17.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tensortrade) (0.2.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tensortrade) (0.36.2)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tensortrade) (1.1.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.1.0->tensortrade) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.1.0->tensortrade) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.1.0->tensortrade) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.1.0->tensortrade) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.1.0->tensortrade) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.1.0->tensortrade) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.1.0->tensortrade) (0.4.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.1.0->tensortrade) (1.32.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.1.0->tensortrade) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.1.0->tensortrade) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.1.0->tensortrade) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.1.0->tensortrade) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.1.0->tensortrade) (4.6.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.1.0->tensortrade) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.1.0->tensortrade) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.1.0->tensortrade) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.1.0->tensortrade) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.1.0->tensortrade) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.1.0->tensortrade) (3.1.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython>=7.12.0->tensortrade) (0.2.0)\n",
            "Collecting int-date>=0.1.7\n",
            "  Downloading int_date-0.1.8-py2.py3-none-any.whl (5.0 kB)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.9)\n",
            "Collecting lxml>=4.5.1\n",
            "  Downloading lxml-4.6.3-cp37-cp37m-manylinux2014_x86_64.whl (6.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 43.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.1.0->tensortrade) (3.5.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[all]) (1.0.2)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[all]) (0.11.0)\n",
            "Collecting aioredis\n",
            "  Downloading aioredis-1.3.1-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[all]) (2.6.0)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[all]) (7.1.2)\n",
            "Collecting redis>=3.5.0\n",
            "  Downloading redis-3.5.3-py2.py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 537 kB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[all]) (3.0.12)\n",
            "Collecting pydantic>=1.8\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 43.0 MB/s \n",
            "\u001b[?25hCollecting opencensus\n",
            "  Downloading opencensus-0.7.13-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 49.4 MB/s \n",
            "\u001b[?25hCollecting aiohttp-cors\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 38.7 MB/s \n",
            "\u001b[?25hCollecting py-spy>=0.2.0\n",
            "  Downloading py_spy-0.3.7-py2.py3-none-manylinux1_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 40.7 MB/s \n",
            "\u001b[?25hCollecting gpustat\n",
            "  Downloading gpustat-0.6.0.tar.gz (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.7 MB/s \n",
            "\u001b[?25hCollecting opentelemetry-sdk==1.1.0\n",
            "  Downloading opentelemetry_sdk-1.1.0-py3-none-any.whl (36 kB)\n",
            "Collecting tensorboardX>=1.9\n",
            "  Downloading tensorboardX-2.4-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[K     |████████████████████████████████| 124 kB 47.3 MB/s \n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp==1.1.0\n",
            "  Downloading opentelemetry_exporter_otlp-1.1.0-py3-none-any.whl (7.3 kB)\n",
            "Collecting starlette\n",
            "  Downloading starlette-0.16.0-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 255 kB/s \n",
            "\u001b[?25hCollecting kopf\n",
            "  Downloading kopf-1.32.1-py3-none-any.whl (196 kB)\n",
            "\u001b[K     |████████████████████████████████| 196 kB 49.5 MB/s \n",
            "\u001b[?25hCollecting opencv-python-headless<=4.3.0.36\n",
            "  Downloading opencv_python_headless-4.3.0.36-cp37-cp37m-manylinux2014_x86_64.whl (36.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 36.4 MB 14 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[all]) (0.8.9)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.14.0-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.6 MB/s \n",
            "\u001b[?25hCollecting opentelemetry-api==1.1.0\n",
            "  Downloading opentelemetry_api-1.1.0-py3-none-any.whl (37 kB)\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.67.0-py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 396 kB/s \n",
            "\u001b[?25hCollecting colorful\n",
            "  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[K     |████████████████████████████████| 201 kB 46.0 MB/s \n",
            "\u001b[?25hCollecting lz4\n",
            "  Downloading lz4-3.1.3-cp37-cp37m-manylinux2010_x86_64.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 44.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from ray[all]) (0.1.6)\n",
            "Collecting kubernetes\n",
            "  Downloading kubernetes-17.17.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 42.1 MB/s \n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc==1.1.0\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-proto==1.1.0\n",
            "  Downloading opentelemetry_proto-1.1.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.7/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.1.0->opentelemetry-exporter-otlp==1.1.0->ray[all]) (1.53.0)\n",
            "Collecting backoff~=1.10.0\n",
            "  Downloading backoff-1.10.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.20b0\n",
            "  Downloading opentelemetry_semantic_conventions-0.20b0-py3-none-any.whl (20 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[K     |████████████████████████████████| 294 kB 46.5 MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 50.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[all]) (21.2.0)\n",
            "Collecting hiredis\n",
            "  Downloading hiredis-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 3.6 MB/s \n",
            "\u001b[?25hCollecting starlette\n",
            "  Downloading starlette-0.14.2-py3-none-any.whl (60 kB)\n",
            "\u001b[K     |████████████████████████████████| 60 kB 242 kB/s \n",
            "\u001b[?25hRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray[all]) (7.352.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat->ray[all]) (5.4.8)\n",
            "Collecting blessings>=1.6\n",
            "  Downloading blessings-1.7-py3-none-any.whl (18 kB)\n",
            "Collecting iso8601\n",
            "  Downloading iso8601-0.1.16-py2.py3-none-any.whl (10 kB)\n",
            "Collecting python-json-logger\n",
            "  Downloading python_json_logger-2.0.2-py3-none-any.whl (7.4 kB)\n",
            "Collecting aiojobs\n",
            "  Downloading aiojobs-0.3.0-py3-none-any.whl (10.0 kB)\n",
            "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0\n",
            "  Downloading websocket_client-1.1.0-py2.py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 7.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[all]) (1.26.3)\n",
            "Collecting opencensus-context==0.1.2\n",
            "  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[all]) (21.0)\n",
            "Collecting h11>=0.8\n",
            "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.1 MB/s \n",
            "\u001b[?25hCollecting asgiref>=3.3.4\n",
            "  Downloading asgiref-3.4.1-py3-none-any.whl (25 kB)\n",
            "Building wheels for collected packages: tensortrade, yfinance, gpustat\n",
            "  Building wheel for tensortrade (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensortrade: filename=tensortrade-1.0.3-py3-none-any.whl size=134871 sha256=fe4b5d0b00dbc39117b650ff1d373fc0fb7d8a3f1e193e363a2318c8f901cc4d\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/3b/2d/997606a2a1e031b57bc2e463154c8df18c1f9a46f6f5536f3f\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yfinance: filename=yfinance-0.1.63-py2.py3-none-any.whl size=23919 sha256=38614cbbe185dd4f2b4b162f31abf130eded29b41f1f958b531fc00ac79b0488\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/87/8b/7ec24486e001d3926537f5f7801f57a74d181be25b11157983\n",
            "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-0.6.0-py3-none-any.whl size=12617 sha256=ce7dc0d389b77ec61053993251ef2aef9584902b5792284984eec016bc248aeb\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/67/af/f1ad15974b8fd95f59a63dbf854483ebe5c7a46a93930798b8\n",
            "Successfully built tensortrade yfinance gpustat\n",
            "Installing collected packages: multidict, yarl, opentelemetry-semantic-conventions, opentelemetry-api, async-timeout, opentelemetry-sdk, opentelemetry-proto, opencensus-context, hiredis, blessings, backoff, aiohttp, websocket-client, tenacity, starlette, redis, pyyaml, python-json-logger, pydantic, py-spy, prompt-toolkit, opentelemetry-exporter-otlp-proto-grpc, opencensus, iso8601, h11, gpustat, colorama, asgiref, aioredis, aiojobs, aiohttp-cors, uvicorn, tensorboardX, stochastic, ray, plotly, opentelemetry-exporter-otlp, opencv-python-headless, lz4, lxml, kubernetes, kopf, ipython, int-date, fastapi, colorful, yfinance, tensortrade, stockstats\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 4.4.1\n",
            "    Uninstalling plotly-4.4.1:\n",
            "      Successfully uninstalled plotly-4.4.1\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 5.5.0\n",
            "    Uninstalling ipython-5.5.0:\n",
            "      Successfully uninstalled ipython-5.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.19 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.25.0 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.7.4.post0 aiohttp-cors-0.7.0 aiojobs-0.3.0 aioredis-1.3.1 asgiref-3.4.1 async-timeout-3.0.1 backoff-1.10.0 blessings-1.7 colorama-0.4.4 colorful-0.5.4 fastapi-0.67.0 gpustat-0.6.0 h11-0.12.0 hiredis-2.0.0 int-date-0.1.8 ipython-7.25.0 iso8601-0.1.16 kopf-1.32.1 kubernetes-17.17.0 lxml-4.6.3 lz4-3.1.3 multidict-5.1.0 opencensus-0.7.13 opencensus-context-0.1.2 opencv-python-headless-4.3.0.36 opentelemetry-api-1.1.0 opentelemetry-exporter-otlp-1.1.0 opentelemetry-exporter-otlp-proto-grpc-1.1.0 opentelemetry-proto-1.1.0 opentelemetry-sdk-1.1.0 opentelemetry-semantic-conventions-0.20b0 plotly-5.1.0 prompt-toolkit-3.0.19 py-spy-0.3.7 pydantic-1.8.2 python-json-logger-2.0.2 pyyaml-5.4.1 ray-1.5.0 redis-3.5.3 starlette-0.14.2 stochastic-0.6.0 stockstats-0.3.2 tenacity-8.0.1 tensorboardX-2.4 tensortrade-1.0.3 uvicorn-0.14.0 websocket-client-1.1.0 yarl-1.6.3 yfinance-0.1.63\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qy3MKaJrfiY-"
      },
      "source": [
        "import ray\n",
        "import numpy as np\n",
        "\n",
        "from ray import tune\n",
        "from ray.tune.registry import register_env\n",
        "\n",
        "import tensortrade.env.default as default\n",
        "\n",
        "from tensortrade.feed.core import DataFeed, Stream\n",
        "from tensortrade.oms.instruments import Instrument, USD\n",
        "from tensortrade.oms.exchanges import Exchange\n",
        "from tensortrade.oms.services.execution.simulated import execute_order\n",
        "from tensortrade.oms.wallets import Wallet, Portfolio\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd \n",
        "from datetime import datetime, timedelta\n",
        "from stockstats import StockDataFrame as Sdf  # for Sdf.retype\n",
        "\n",
        "class FeatureEngineer:\n",
        "    \"\"\"Provides methods for preprocessing the stock price data\n",
        "    from finrl.preprocessing.preprocessors import FeatureEngineer\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        use_technical_indicator : boolean\n",
        "            we technical indicator or not\n",
        "        tech_indicator_list : list\n",
        "            a list of technical indicator names (modified from config.py)\n",
        "        use_turbulence : boolean\n",
        "            use turbulence index or not\n",
        "        user_defined_feature:boolean\n",
        "            user user defined features or not\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    preprocess_data()\n",
        "        main method to do the feature engineering\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            use_technical_indicator=True,\n",
        "            tech_indicator_list=None,  # config.TECHNICAL_INDICATORS_LIST,\n",
        "            use_turbulence=False,\n",
        "            user_defined_feature=False,\n",
        "    ):\n",
        "        self.use_technical_indicator = use_technical_indicator\n",
        "        self.tech_indicator_list = tech_indicator_list\n",
        "        self.use_turbulence = use_turbulence\n",
        "        self.user_defined_feature = user_defined_feature\n",
        "\n",
        "    def preprocess_data(self, df):\n",
        "        \"\"\"main method to do the feature engineering\n",
        "        @:param config: source dataframe\n",
        "        @:return: a DataMatrices object\n",
        "        \"\"\"\n",
        "\n",
        "        if self.use_technical_indicator:\n",
        "            # add technical indicators using stockstats\n",
        "            df = self.add_technical_indicator(df)\n",
        "            print(\"Successfully added technical indicators\")\n",
        "\n",
        "        # add turbulence index for multiple stock\n",
        "        if self.use_turbulence:\n",
        "            df = self.add_turbulence(df)\n",
        "            print(\"Successfully added turbulence index\")\n",
        "\n",
        "        # add user defined feature\n",
        "        if self.user_defined_feature:\n",
        "            df = self.add_user_defined_feature(df)\n",
        "            print(\"Successfully added user defined features\")\n",
        "\n",
        "        # fill the missing values at the beginning and the end\n",
        "        df = df.fillna(method=\"bfill\").fillna(method=\"ffill\")\n",
        "        return df\n",
        "\n",
        "    def add_technical_indicator(self, data):\n",
        "        \"\"\"\n",
        "        calculate technical indicators\n",
        "        use stockstats package to add technical inidactors\n",
        "        :param data: (df) pandas dataframe\n",
        "        :return: (df) pandas dataframe\n",
        "        \"\"\"\n",
        "        from stockstats import StockDataFrame as Sdf  # for Sdf.retype\n",
        "\n",
        "        df = data.copy()\n",
        "        df = df.sort_values(by=['tic', 'date'])\n",
        "        stock = Sdf.retype(df.copy())\n",
        "        unique_ticker = stock.tic.unique()\n",
        "\n",
        "        for indicator in self.tech_indicator_list:\n",
        "            indicator_df = pd.DataFrame()\n",
        "            for i in range(len(unique_ticker)):\n",
        "                try:\n",
        "                    temp_indicator = stock[stock.tic == unique_ticker[i]][indicator]\n",
        "                    temp_indicator = pd.DataFrame(temp_indicator)\n",
        "                    temp_indicator['tic'] = unique_ticker[i]\n",
        "                    temp_indicator['date'] = df[df.tic == unique_ticker[i]]['date'].to_list()\n",
        "                    indicator_df = indicator_df.append(\n",
        "                        temp_indicator, ignore_index=True\n",
        "                    )\n",
        "                except Exception as e:\n",
        "                    print(e)\n",
        "            df = df.merge(indicator_df[['tic', 'date', indicator]], on=['tic', 'date'], how='left')\n",
        "        df = df.sort_values(by=['date', 'tic'])\n",
        "        return df\n",
        "\n",
        "    def add_turbulence(self, data):\n",
        "        \"\"\"\n",
        "        add turbulence index from a precalcualted dataframe\n",
        "        :param data: (df) pandas dataframe\n",
        "        :return: (df) pandas dataframe\n",
        "        \"\"\"\n",
        "        df = data.copy()\n",
        "        turbulence_index = self.calculate_turbulence(df)\n",
        "        df = df.merge(turbulence_index, on=\"date\")\n",
        "        df = df.sort_values([\"date\", \"tic\"]).reset_index(drop=True)\n",
        "        return df\n",
        "\n",
        "    @staticmethod\n",
        "    def add_user_defined_feature(data):\n",
        "        \"\"\"\n",
        "         add user defined features\n",
        "        :param data: (df) pandas dataframe\n",
        "        :return: (df) pandas dataframe\n",
        "        \"\"\"\n",
        "        df = data.copy()\n",
        "        df[\"daily_return\"] = df.close.pct_change(1)\n",
        "        # df['return_lag_1']=df.close.pct_change(2)\n",
        "        # df['return_lag_2']=df.close.pct_change(3)\n",
        "        # df['return_lag_3']=df.close.pct_change(4)\n",
        "        # df['return_lag_4']=df.close.pct_change(5)\n",
        "        return df\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_turbulence(data):\n",
        "        \"\"\"calculate turbulence index based on dow 30\"\"\"\n",
        "        # can add other market assets\n",
        "        df = data.copy()\n",
        "        df_price_pivot = df.pivot(index=\"date\", columns=\"tic\", values=\"close\")\n",
        "        # use returns to calculate turbulence\n",
        "        df_price_pivot = df_price_pivot.pct_change()\n",
        "\n",
        "        unique_date = df.date.unique()\n",
        "        # start after a year\n",
        "        start = 252\n",
        "        turbulence_index = [0] * start\n",
        "        # turbulence_index = [0]\n",
        "        count = 0\n",
        "        for i in range(start, len(unique_date)):\n",
        "            current_price = df_price_pivot[df_price_pivot.index == unique_date[i]]\n",
        "            # use one year rolling window to calcualte covariance\n",
        "            hist_price = df_price_pivot[\n",
        "                (df_price_pivot.index < unique_date[i])\n",
        "                & (df_price_pivot.index >= unique_date[i - 252])\n",
        "                ]\n",
        "            # Drop tickers which has number missing values more than the \"oldest\" ticker\n",
        "            filtered_hist_price = hist_price.iloc[hist_price.isna().sum().min():].dropna(axis=1)\n",
        "\n",
        "            cov_temp = filtered_hist_price.cov()\n",
        "            current_temp = current_price[[x for x in filtered_hist_price]] - np.mean(filtered_hist_price, axis=0)\n",
        "            temp = current_temp.values.dot(np.linalg.pinv(cov_temp)).dot(\n",
        "                current_temp.values.T\n",
        "            )\n",
        "            if temp > 0:\n",
        "                count += 1\n",
        "                if count > 2:\n",
        "                    turbulence_temp = temp[0][0]\n",
        "                else:\n",
        "                    # avoid large outlier because of the calculation just begins\n",
        "                    turbulence_temp = 0\n",
        "            else:\n",
        "                turbulence_temp = 0\n",
        "            turbulence_index.append(turbulence_temp)\n",
        "\n",
        "        turbulence_index = pd.DataFrame(\n",
        "            {\"date\": df_price_pivot.index, \"turbulence\": turbulence_index}\n",
        "        )\n",
        "        return turbulence_index\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AvvKBzbf2Hg"
      },
      "source": [
        "tickers = [\n",
        "'AAPL', 'ADBE', 'ADI', 'ADP', 'ADSK', 'ALGN',  'AMAT', 'AMD', 'AMGN',\n",
        "'AMZN', 'ASML', 'ATVI', 'BIIB', 'BKNG', 'BMRN', 'CDNS', 'CERN', 'CHKP', 'CMCSA',\n",
        "'COST', 'CSCO', 'CSX', 'CTAS', 'CTSH', 'CTXS', 'DLTR', 'EA', 'EBAY', 'FAST',\n",
        "'FISV', 'GILD', 'HAS', 'HSIC', 'IDXX', 'ILMN', 'INCY', 'INTC', 'INTU', 'ISRG',\n",
        "'JBHT', 'KLAC', 'LRCX', 'MAR', 'MCHP', 'MDLZ', 'MNST', 'MSFT', 'MU', 'MXIM',\n",
        "'NLOK', 'NTAP', 'NTES', 'NVDA', 'ORLY', 'PAYX', 'PCAR', 'PEP', 'QCOM', 'REGN',\n",
        "'ROST', 'SBUX', 'SIRI', 'SNPS', 'SWKS', 'TTWO', 'TXN', 'VRSN', 'VRTX', 'WBA',\n",
        "'WDC', 'WLTW', 'XEL', 'XLNX']  # finrl.config.NAS_74_TICKER\n",
        "\n",
        "tech_indicator_list = [\n",
        "'macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30',\n",
        "'close_30_sma', 'close_60_sma']  # finrl.config.TECHNICAL_INDICATORS_LIST\n",
        "\n",
        "# _ = remove_old_data()\n",
        "\n",
        "start_date = '2008-01-01'\n",
        "start_eval_date = (datetime.now() - timedelta(days=365*1)).strftime(\"%F\")\n",
        "end_eval_date = datetime.now().strftime('%F')\n",
        "\n",
        "def get_data(start_date, end_date, tickers, tech_indicator_list):\n",
        "\n",
        "    data_df = pd.DataFrame()\n",
        "    for tic in tickers:\n",
        "        temp_df = yf.download(tic, start=start_date, end=end_eval_date)\n",
        "        temp_df[\"tic\"] = tic\n",
        "        data_df = data_df.append(temp_df)\n",
        "    # reset the index, we want to use numbers as index instead of dates\n",
        "    data_df = data_df.reset_index()\n",
        "    # convert the column names to standardized names\n",
        "    data_df.columns = [\n",
        "        \"date\",\n",
        "        \"open\",\n",
        "        \"high\",\n",
        "        \"low\",\n",
        "        \"close\",\n",
        "        \"adjcp\",\n",
        "        \"volume\",\n",
        "        \"tic\",\n",
        "    ]\n",
        "    # use adjusted close price instead of close price\n",
        "    data_df[\"close\"] = data_df[\"adjcp\"]\n",
        "    # drop the adjusted close price column\n",
        "    data_df = data_df.drop(\"adjcp\", 1)\n",
        "    # create day of the week column (monday = 0)\n",
        "    data_df[\"day\"] = data_df[\"date\"].dt.dayofweek\n",
        "    # convert date to standard string format, easy to filter\n",
        "    data_df[\"date\"] = data_df.date.apply(lambda x: x.strftime(\"%Y-%m-%d\"))\n",
        "    # drop missing data\n",
        "    data_df = data_df.dropna()\n",
        "    data_df = data_df.reset_index(drop=True)\n",
        "    print(\"Shape of DataFrame: \", data_df.shape)\n",
        "    # print(\"Display DataFrame: \", data_df.head())\n",
        "\n",
        "    data_df = data_df.sort_values(by=['date', 'tic']).reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "    fe = FeatureEngineer(use_turbulence=True,\n",
        "                            user_defined_feature=False,\n",
        "                            use_technical_indicator=True,\n",
        "                            tech_indicator_list=tech_indicator_list, )\n",
        "\n",
        "    processed_df = fe.preprocess_data(data_df)\n",
        "    return processed_df\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MdIJqK94f4cR",
        "outputId": "d27e1985-ef78-426d-fd66-5296eaace894"
      },
      "source": [
        "def create_env(config): \n",
        "\n",
        "\n",
        "  df = get_data(start_date, end_eval_date, tickers, tech_indicator_list)\n",
        "\n",
        "  USD.precision = 6\n",
        "  features = []\n",
        "  for key, group in df.groupby('tic'):\n",
        "      for column in group.columns:\n",
        "          if column in {'date','tic'} : \n",
        "              continue\n",
        "          s = Stream.source(group[column].values.tolist(), dtype=float).rename(key+'_'+column)\n",
        "          features.append(s)\n",
        "\n",
        "  feed = DataFeed(features)\n",
        "  feed.compile()\n",
        "\n",
        "  prices = []\n",
        "  for key, group in df.groupby('tic'):\n",
        "      s = Stream.source(group['close'].values.tolist(), dtype=float).rename('USD/' + key)\n",
        "      prices.append(s)\n",
        "\n",
        "  exchange = Exchange(\"alpaca\", service=execute_order)(*prices)\n",
        "\n",
        "  stonks = [Instrument(x, 6, x) for x in tickers]\n",
        "  cash = 2000.\n",
        "  starting_cash = Wallet(exchange, cash * USD )\n",
        "  #initialize no owned stocks\n",
        "  wallets = [starting_cash] + [Wallet(exchange, 0*x) for x in stonks]\n",
        "\n",
        "  portfolio = Portfolio(\n",
        "      base_instrument=USD,\n",
        "      wallets=wallets\n",
        "  )\n",
        "  env = default.create(\n",
        "    feed=feed,\n",
        "    portfolio=portfolio,\n",
        "    action_scheme=\"managed-risk\",\n",
        "    reward_scheme=\"risk-adjusted\",\n",
        "    window_size=25,\n",
        "    max_allowed_loss=0.6\n",
        "  )\n",
        "  return env   \n",
        "\n",
        "register_env(\"TradingEnv\", create_env)\n",
        "\n",
        "\n",
        "analysis = tune.run(\n",
        "    \"PPO\",\n",
        "    stop={\n",
        "      \"episode_reward_mean\": 500\n",
        "    },\n",
        "    reuse_actors=True,\n",
        "    config={\n",
        "        \"env\": \"TradingEnv\",\n",
        "        \"env_config\": {\n",
        "            \"window_size\": 25\n",
        "        },\n",
        "        \"log_level\": \"DEBUG\",\n",
        "        \"framework\": \"torch\",\n",
        "        \"ignore_worker_failures\": True,\n",
        "        \"num_workers\": 1,\n",
        "        \"num_gpus\": 1,\n",
        "        \"clip_rewards\": True,\n",
        "        \"lr\": 8e-6,\n",
        "        \"lr_schedule\": [\n",
        "            [0, 1e-1],\n",
        "            [int(1e2), 1e-2],\n",
        "            [int(1e3), 1e-3],\n",
        "            [int(1e4), 1e-4],\n",
        "            [int(1e5), 1e-5],\n",
        "            [int(1e6), 1e-6],\n",
        "            [int(1e7), 1e-7]\n",
        "        ],\n",
        "        \"gamma\": 0,\n",
        "        \"observation_filter\": \"MeanStdFilter\",\n",
        "        \"lambda\": 0.72,\n",
        "        \"vf_loss_coeff\": 0.5,\n",
        "        \"entropy_coeff\": 0.01\n",
        "    },\n",
        "    checkpoint_at_end=True\n",
        ")\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 4.3/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 GPU_group_0_ffbb7d72448614970ca428d3f2907b51, 0.0/1.0 GPU_group_ffbb7d72448614970ca428d3f2907b51, 0.0/1.0 CPU_group_0_ffbb7d72448614970ca428d3f2907b51, 0.0/1.0 CPU_group_1_ffbb7d72448614970ca428d3f2907b51, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_ffbb7d72448614970ca428d3f2907b51)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                </th><th>status  </th><th>loc  </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_TradingEnv_f49fd_00000</td><td>PENDING </td><td>     </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m Shape of DataFrame:  (249368, 8)\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m Successfully added technical indicators\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m Successfully added turbulence index\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-07-28 11:25:34,460\tDEBUG rollout_worker.py:1303 -- Creating policy for default_policy\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-07-28 11:25:34,461\tDEBUG catalog.py:708 -- Created preprocessor <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7f40952c9f90>: Box(-inf, inf, (25, 1095), float32) -> (25, 1095)\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-07-28 11:25:34,819\tINFO torch_policy.py:139 -- TorchPolicy (worker=1) running on CPU.\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-07-28 11:25:35,165\tDEBUG rollout_worker.py:572 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-07-28 11:25:35,166\tDEBUG rollout_worker.py:713 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f40a5602250> (<TradingEnv instance>), policies {'default_policy': <ray.rllib.policy.policy_template.PPOTorchPolicy object at 0x7f40a55fe950>}\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m 2021-07-28 11:25:35,176\tDEBUG rollout_worker.py:1303 -- Creating policy for default_policy\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m 2021-07-28 11:25:35,178\tDEBUG catalog.py:708 -- Created preprocessor <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7f0e6e27e7d0>: Box(-inf, inf, (25, 1095), float32) -> (25, 1095)\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m 2021-07-28 11:25:35,570\tINFO torch_policy.py:151 -- TorchPolicy (worker=local) running on 1 GPU(s).\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m 2021-07-28 11:25:38,781\tINFO rollout_worker.py:1344 -- Built policy map: {'default_policy': <ray.rllib.policy.policy_template.PPOTorchPolicy object at 0x7f0e6e49d490>}\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m 2021-07-28 11:25:38,781\tINFO rollout_worker.py:1345 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7f0e6e27e7d0>}\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m 2021-07-28 11:25:38,782\tINFO rollout_worker.py:602 -- Built filter map: {'default_policy': MeanStdFilter((25, 1095), True, True, None, (n=0, mean_mean=0.0, mean_std=0.0), (n=0, mean_mean=0.0, mean_std=0.0))}\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m 2021-07-28 11:25:38,782\tDEBUG rollout_worker.py:713 -- Created rollout worker with env None (None), policies {'default_policy': <ray.rllib.policy.policy_template.PPOTorchPolicy object at 0x7f0e6e49d490>}\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-07-28 11:25:38,868\tINFO rollout_worker.py:737 -- Generating sample batch of size 200\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-07-28 11:25:38,869\tDEBUG sampler.py:542 -- No episode horizon specified, assuming inf.\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-07-28 11:25:38,886\tINFO sampler.py:593 -- Raw obs from env: { 0: { 'agent0': np.ndarray((25, 1095), dtype=float32, min=-66.667, max=1079178752.0, mean=70535.625)}}\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-07-28 11:25:38,886\tINFO sampler.py:594 -- Info return from env: {0: {'agent0': None}}\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-07-28 11:25:38,886\tINFO sampler.py:823 -- Preprocessed obs: np.ndarray((25, 1095), dtype=float32, min=-66.667, max=1079178752.0, mean=70535.625)\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-07-28 11:25:38,887\tINFO sampler.py:827 -- Filtered obs: np.ndarray((25, 1095), dtype=float64, min=0.0, max=0.0, mean=0.0)\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-07-28 11:25:38,888\tINFO sampler.py:1017 -- Inputs to compute_actions():\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m                                   'env_id': 0,\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m                                   'info': None,\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m                                   'obs': np.ndarray((25, 1095), dtype=float64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m                                   'prev_action': None,\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m                                   'prev_reward': None,\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m                                   'rnn_state': None},\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m                         'type': 'PolicyEvalData'}]}\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-07-28 11:25:38,899\tINFO sampler.py:1043 -- Outputs of compute_actions():\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m { 'default_policy': ( np.ndarray((1,), dtype=int64, min=10587.0, max=10587.0, mean=10587.0),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m                       [],\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m                       { 'action_dist_inputs': np.ndarray((1, 13141), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m                         'action_logp': np.ndarray((1,), dtype=float32, min=-9.483, max=-9.483, mean=-9.483),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m                         'action_prob': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0)})}\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m 2021-07-28 11:25:38,841\tINFO trainable.py:109 -- Trainable.setup took 242.632 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m 2021-07-28 11:25:38,842\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-07-28 11:25:43,701\tINFO simple_list_collector.py:661 -- Trajectory fragment after postprocess_trajectory():\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m { 'agent0': { 'action_dist_inputs': np.ndarray((200, 13141), dtype=float32, min=-0.024, max=0.025, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m               'action_logp': np.ndarray((200,), dtype=float32, min=-9.502, max=-9.472, mean=-9.484),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m               'actions': np.ndarray((200,), dtype=int64, min=13.0, max=13069.0, mean=7199.625),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m               'advantages': np.ndarray((200,), dtype=float32, min=-1.011, max=1.01, mean=-0.071),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m               'agent_index': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m               'dones': np.ndarray((200,), dtype=bool, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m               'eps_id': np.ndarray((200,), dtype=int64, min=1741137258.0, max=1741137258.0, mean=1741137258.0),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m               'infos': np.ndarray((200,), dtype=object, head={'step': 1, 'net_worth': 1996.2458838171274}),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m               'new_obs': np.ndarray((200, 25, 1095), dtype=float32, min=-6.236, max=11.2, mean=0.265),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m               'obs': np.ndarray((200, 25, 1095), dtype=float32, min=-6.236, max=11.2, mean=0.266),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m               'rewards': np.ndarray((200,), dtype=float32, min=-1.0, max=1.0, mean=-0.07),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m               'unroll_id': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m               'value_targets': np.ndarray((200,), dtype=float32, min=-1.0, max=1.0, mean=-0.07),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m               'vf_preds': np.ndarray((200,), dtype=float32, min=-0.01, max=0.012, mean=0.001)}}\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-07-28 11:25:43,741\tINFO rollout_worker.py:775 -- Completed sample batch:\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m { 'action_dist_inputs': np.ndarray((200, 13141), dtype=float32, min=-0.024, max=0.025, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m   'action_logp': np.ndarray((200,), dtype=float32, min=-9.502, max=-9.472, mean=-9.484),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m   'actions': np.ndarray((200,), dtype=int64, min=13.0, max=13069.0, mean=7199.625),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m   'advantages': np.ndarray((200,), dtype=float32, min=-1.011, max=1.01, mean=-0.071),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m   'agent_index': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m   'dones': np.ndarray((200,), dtype=bool, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m   'eps_id': np.ndarray((200,), dtype=int64, min=1741137258.0, max=1741137258.0, mean=1741137258.0),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m   'infos': np.ndarray((200,), dtype=object, head={'step': 1, 'net_worth': 1996.2458838171274}),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m   'new_obs': np.ndarray((200, 25, 1095), dtype=float32, min=-6.236, max=11.2, mean=0.265),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m   'obs': np.ndarray((200, 25, 1095), dtype=float32, min=-6.236, max=11.2, mean=0.266),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m   'rewards': np.ndarray((200,), dtype=float32, min=-1.0, max=1.0, mean=-0.07),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m   'unroll_id': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m   'value_targets': np.ndarray((200,), dtype=float32, min=-1.0, max=1.0, mean=-0.07),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m   'vf_preds': np.ndarray((200,), dtype=float32, min=-0.01, max=0.012, mean=0.001)}\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-07-28 11:26:43,736\tINFO sampler.py:593 -- Raw obs from env: { 0: { 'agent0': np.ndarray((25, 1095), dtype=float32, min=-379.037, max=174302592.0, mean=647879.75)}}\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-07-28 11:26:43,737\tINFO sampler.py:594 -- Info return from env: { 0: { 'agent0': { 'net_worth': 13186.233350698141,\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m                    'step': 2586}}}\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-07-28 11:26:43,737\tINFO sampler.py:823 -- Preprocessed obs: np.ndarray((25, 1095), dtype=float32, min=-379.037, max=174302592.0, mean=647879.75)\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-07-28 11:26:43,738\tINFO sampler.py:827 -- Filtered obs: np.ndarray((25, 1095), dtype=float64, min=-5.337, max=16.242, mean=1.133)\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-07-28 11:26:43,739\tINFO sampler.py:1017 -- Inputs to compute_actions():\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m                                   'env_id': 0,\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m                                   'info': { 'net_worth': 13186.233350698141,\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m                                             'step': 2586},\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m                                   'obs': np.ndarray((25, 1095), dtype=float64, min=-5.337, max=16.242, mean=1.133),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m                                   'prev_action': 5869,\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m                                   'prev_reward': -2852687.423562122,\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m                                   'rnn_state': []},\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m                         'type': 'PolicyEvalData'}]}\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-07-28 11:26:43,750\tINFO sampler.py:1043 -- Outputs of compute_actions():\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m { 'default_policy': ( np.ndarray((1,), dtype=int64, min=10367.0, max=10367.0, mean=10367.0),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m                       [],\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m                       { 'action_dist_inputs': np.ndarray((1, 13141), dtype=float32, min=-0.028, max=0.022, mean=-0.0),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m                         'action_logp': np.ndarray((1,), dtype=float32, min=-9.478, max=-9.478, mean=-9.478),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m                         'action_prob': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0)})}\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-07-28 11:26:44,172\tINFO simple_list_collector.py:661 -- Trajectory fragment after postprocess_trajectory():\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m { 'agent0': { 'action_dist_inputs': np.ndarray((200, 13141), dtype=float32, min=-0.028, max=0.027, mean=-0.0),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m               'action_logp': np.ndarray((200,), dtype=float32, min=-9.496, max=-9.467, mean=-9.484),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m               'actions': np.ndarray((200,), dtype=int64, min=37.0, max=13111.0, mean=6311.28),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m               'advantages': np.ndarray((200,), dtype=float32, min=-1.005, max=1.005, mean=0.039),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m               'agent_index': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m               'dones': np.ndarray((200,), dtype=bool, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m               'eps_id': np.ndarray((200,), dtype=int64, min=1741137258.0, max=1741137258.0, mean=1741137258.0),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m               'infos': np.ndarray((200,), dtype=object, head={'step': 2401, 'net_worth': 13214.841771800413}),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m               'new_obs': np.ndarray((200, 25, 1095), dtype=float32, min=-8.668, max=19.206, mean=1.26),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m               'obs': np.ndarray((200, 25, 1095), dtype=float32, min=-8.668, max=19.206, mean=1.261),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m               'rewards': np.ndarray((200,), dtype=float32, min=-1.0, max=1.0, mean=0.04),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m               'unroll_id': np.ndarray((200,), dtype=int64, min=12.0, max=12.0, mean=12.0),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m               'value_targets': np.ndarray((200,), dtype=float32, min=-1.0, max=1.0, mean=0.04),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m               'vf_preds': np.ndarray((200,), dtype=float32, min=-0.005, max=0.006, mean=0.001)}}\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-07-28 11:26:44,207\tINFO rollout_worker.py:775 -- Completed sample batch:\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m { 'action_dist_inputs': np.ndarray((200, 13141), dtype=float32, min=-0.028, max=0.027, mean=-0.0),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m   'action_logp': np.ndarray((200,), dtype=float32, min=-9.496, max=-9.467, mean=-9.484),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m   'actions': np.ndarray((200,), dtype=int64, min=37.0, max=13111.0, mean=6311.28),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m   'advantages': np.ndarray((200,), dtype=float32, min=-1.005, max=1.005, mean=0.039),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m   'agent_index': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m   'dones': np.ndarray((200,), dtype=bool, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m   'eps_id': np.ndarray((200,), dtype=int64, min=1741137258.0, max=1741137258.0, mean=1741137258.0),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m   'infos': np.ndarray((200,), dtype=object, head={'step': 2401, 'net_worth': 13214.841771800413}),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m   'new_obs': np.ndarray((200, 25, 1095), dtype=float32, min=-8.668, max=19.206, mean=1.26),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m   'obs': np.ndarray((200, 25, 1095), dtype=float32, min=-8.668, max=19.206, mean=1.261),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m   'rewards': np.ndarray((200,), dtype=float32, min=-1.0, max=1.0, mean=0.04),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m   'unroll_id': np.ndarray((200,), dtype=int64, min=12.0, max=12.0, mean=12.0),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m   'value_targets': np.ndarray((200,), dtype=float32, min=-1.0, max=1.0, mean=0.04),\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m   'vf_preds': np.ndarray((200,), dtype=float32, min=-0.005, max=0.006, mean=0.001)}\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-07-28 11:26:44,234\tINFO rollout_worker.py:737 -- Generating sample batch of size 200\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m 2021-07-28 11:27:20,965\tINFO rollout_worker.py:916 -- Training on concatenated sample batches:\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m { 'count': 128,\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m   'policy_batches': { 'default_policy': { 'action_dist_inputs': np.ndarray((128, 13141), dtype=float32, min=-0.027, max=0.027, mean=-0.0),\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m                                           'action_logp': np.ndarray((128,), dtype=float32, min=-9.496, max=-9.47, mean=-9.483),\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m                                           'actions': np.ndarray((128,), dtype=int64, min=64.0, max=13134.0, mean=7108.977),\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m                                           'advantages': np.ndarray((128,), dtype=float32, min=-1.076, max=0.945, mean=0.012),\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m                                           'agent_index': np.ndarray((128,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m                                           'dones': np.ndarray((128,), dtype=bool, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m                                           'eps_id': np.ndarray((128,), dtype=int64, min=1741137258.0, max=1972355998.0, mean=1777265186.125),\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m                                           'infos': np.ndarray((128,), dtype=object, head={'step': 2759, 'net_worth': 10550.841648348402}),\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m                                           'new_obs': np.ndarray((128, 25, 1095), dtype=float32, min=-15.766, max=39.56, mean=0.625),\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m                                           'obs': np.ndarray((128, 25, 1095), dtype=float32, min=-15.764, max=39.554, mean=0.626),\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m                                           'rewards': np.ndarray((128,), dtype=float32, min=-1.0, max=1.0, mean=0.078),\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m                                           'unroll_id': np.ndarray((128,), dtype=int64, min=0.0, max=20.0, mean=9.859),\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m                                           'value_targets': np.ndarray((128,), dtype=float32, min=-1.0, max=1.0, mean=0.078),\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m                                           'vf_preds': np.ndarray((128,), dtype=float32, min=-0.008, max=0.008, mean=0.001)}},\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m   'type': 'MultiAgentBatch'}\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m 2021-07-28 11:27:20,988\tDEBUG rollout_worker.py:942 -- Training out:\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m { 'default_policy': { 'custom_metrics': {},\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m                       'learner_stats': { 'allreduce_latency': 0.0,\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m                                          'cur_kl_coeff': 0.2,\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m                                          'cur_lr': 0.1,\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m                                          'entropy': 9.483478546142578,\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m                                          'entropy_coeff': 0.01,\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m                                          'kl': -1.4864104613820928e-08,\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m                                          'policy_loss': -0.012164711952209473,\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m                                          'total_loss': 0.3930895924568176,\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m                                          'vf_explained_var': np.ndarray((1,), dtype=float32, min=-0.0, max=-0.0, mean=-0.0),\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m                                          'vf_loss': 1.0001782178878784},\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m                       'model': {}}}\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_TradingEnv_f49fd_00000:\n",
            "  agent_timesteps_total: 4000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-07-28_11-27-45\n",
            "  done: true\n",
            "  episode_len_mean: 3415.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 2901253642.015273\n",
            "  episode_reward_mean: 2901253642.015273\n",
            "  episode_reward_min: 2901253642.015273\n",
            "  episodes_this_iter: 1\n",
            "  episodes_total: 1\n",
            "  experiment_id: 6f9531363cee41fd82fca399955dcab6\n",
            "  hostname: 87106c5b19d3\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        learner_stats:\n",
            "          allreduce_latency: 0.0\n",
            "          cur_kl_coeff: 0.20000000000000004\n",
            "          cur_lr: 0.10000000000000002\n",
            "          entropy: 9.479744375745456\n",
            "          entropy_coeff: 0.01\n",
            "          kl: 0.0036417181546897306\n",
            "          policy_loss: -0.13502408539643512\n",
            "          total_loss: 0.21838097074069082\n",
            "          vf_explained_var: 0.10256961733102798\n",
            "          vf_loss: 0.8949483097220461\n",
            "        model: {}\n",
            "    num_agent_steps_sampled: 4000\n",
            "    num_steps_sampled: 4000\n",
            "    num_steps_trained: 4000\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 57.42430939226519\n",
            "    ram_util_percent: 36.57127071823204\n",
            "  pid: 3258\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.09213319810382488\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 12.85218268863799\n",
            "    mean_inference_ms: 10.877169361414834\n",
            "    mean_raw_obs_processing_ms: 1.3396278735072398\n",
            "  time_since_restore: 126.85442018508911\n",
            "  time_this_iter_s: 126.85442018508911\n",
            "  time_total_s: 126.85442018508911\n",
            "  timers:\n",
            "    learn_throughput: 159.818\n",
            "    learn_time_ms: 25028.486\n",
            "    sample_throughput: 39.308\n",
            "    sample_time_ms: 101760.021\n",
            "    update_time_ms: 39.028\n",
            "  timestamp: 1627471665\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 4000\n",
            "  training_iteration: 1\n",
            "  trial_id: f49fd_00000\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m 2021-07-28 11:27:45,702\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 290125364.0x the scale of `vf_clip_param`. This means that it will take more than 290125364.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
            "\u001b[2m\u001b[36m(pid=3258)\u001b[0m 2021-07-28 11:27:45,712\tDEBUG trainer.py:661 -- synchronized filters: {'default_policy': MeanStdFilter((25, 1095), True, True, None, (n=4002, mean_mean=984446.9169048974, mean_std=774259.1582398375), (n=0, mean_mean=0.0, mean_std=0.0))}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 4.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 GPU_group_0_ffbb7d72448614970ca428d3f2907b51, 0.0/1.0 GPU_group_ffbb7d72448614970ca428d3f2907b51, 0.0/1.0 CPU_group_0_ffbb7d72448614970ca428d3f2907b51, 0.0/1.0 CPU_group_1_ffbb7d72448614970ca428d3f2907b51, 0.0/1.0 accelerator_type:P100, 0.0/2.0 CPU_group_ffbb7d72448614970ca428d3f2907b51)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">     reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_TradingEnv_f49fd_00000</td><td>RUNNING </td><td>172.28.0.2:3258</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         126.854</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\">2.90125e+09</td><td style=\"text-align: right;\">         2.90125e+09</td><td style=\"text-align: right;\">         2.90125e+09</td><td style=\"text-align: right;\">              3415</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 4.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 GPU_group_b81422fa94efd30842e9a39acb32cd45, 0.0/2.0 CPU_group_b81422fa94efd30842e9a39acb32cd45, 0.0/1.0 CPU_group_1_b81422fa94efd30842e9a39acb32cd45, 0.0/1.0 accelerator_type:P100, 0.0/1.0 GPU_group_0_b81422fa94efd30842e9a39acb32cd45, 0.0/1.0 CPU_group_0_b81422fa94efd30842e9a39acb32cd45)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">     reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_TradingEnv_f49fd_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         126.854</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\">2.90125e+09</td><td style=\"text-align: right;\">         2.90125e+09</td><td style=\"text-align: right;\">         2.90125e+09</td><td style=\"text-align: right;\">              3415</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-28 11:27:46,563\tINFO tune.py:550 -- Total run time: 376.75 seconds (376.56 seconds for the tuning loop).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3yscpu_hMd2",
        "outputId": "7b060c16-dae3-4739-a297-99bfe5cadf95"
      },
      "source": [
        "analysis\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7fb0c4240ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "1SVDzOM_3zQM",
        "outputId": "74be0e9a-368b-4fc4-db38-74a97f1a7844"
      },
      "source": [
        "analysis.best_result\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e2bab6391660>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/tune/analysis/experiment_analysis.py\u001b[0m in \u001b[0;36mbest_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_metric\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m             raise ValueError(\n\u001b[0;32m--> 536\u001b[0;31m                 \u001b[0;34m\"To fetch the `best_result`, pass a `metric` and `mode` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m                 \u001b[0;34m\"parameter to `tune.run()`. Alternatively, use \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m                 \u001b[0;34m\"`get_best_trial(metric, mode).last_result` to set \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: To fetch the `best_result`, pass a `metric` and `mode` parameter to `tune.run()`. Alternatively, use `get_best_trial(metric, mode).last_result` to set the metric and mode explicitly and fetch the last result."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qthi8zU-32AR",
        "outputId": "10e9ebc8-5b8a-4051-c468-187e3e035588"
      },
      "source": [
        "\n",
        "import ray.rllib.agents.ppo as ppo\n",
        "\n",
        "analysis.default_mode = 'restore'\n",
        "checkpoints = analysis.get_trial_checkpoints_paths(\n",
        "    trial=analysis.get_best_trial(\"episode_reward_mean\"),\n",
        "    metric=\"episode_reward_mean\"\n",
        ")\n",
        "checkpoint_path = checkpoints[0][0]\n",
        "\n",
        "#checkpoint_path = '/root/ray_results/PPO/PPO_TradingEnv_eba7e_00000_0_2021-07-28_01-29-50/checkpoint_000014/checkpoint-14'\n",
        "\n",
        "# Restore agent\n",
        "agent = ppo.PPOTrainer(\n",
        "    env=\"TradingEnv\",\n",
        "    config={\n",
        "        \"env_config\": {\n",
        "            \"window_size\": 25\n",
        "        },\n",
        "        \"framework\": \"torch\",\n",
        "        \"log_level\": \"DEBUG\",\n",
        "        \"ignore_worker_failures\": True,\n",
        "        \"num_workers\": 4,\n",
        "        \"num_gpus\": 0,\n",
        "        \"clip_rewards\": True,\n",
        "        \"lr\": 8e-6,\n",
        "        \"lr_schedule\": [\n",
        "            [0, 1e-1],\n",
        "            [int(1e2), 1e-2],\n",
        "            [int(1e3), 1e-3],\n",
        "            [int(1e4), 1e-4],\n",
        "            [int(1e5), 1e-5],\n",
        "            [int(1e6), 1e-6],\n",
        "            [int(1e7), 1e-7]\n",
        "        ],\n",
        "        \"gamma\": 0,\n",
        "        \"observation_filter\": \"MeanStdFilter\",\n",
        "        \"lambda\": 0.72,\n",
        "        \"vf_loss_coeff\": 0.5,\n",
        "        \"entropy_coeff\": 0.01\n",
        "    }\n",
        ")\n",
        "agent.restore(checkpoint_path)\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=3866)\u001b[0m \r[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "\u001b[2m\u001b[36m(pid=3867)\u001b[0m Shape of DataFrame:  (249368, 8)\n",
            "\u001b[2m\u001b[36m(pid=3866)\u001b[0m Shape of DataFrame:  (249368, 8)\n",
            "\u001b[2m\u001b[36m(pid=3866)\u001b[0m Successfully added technical indicators\n",
            "\u001b[2m\u001b[36m(pid=3867)\u001b[0m Successfully added technical indicators\n",
            "\u001b[2m\u001b[36m(pid=3866)\u001b[0m Successfully added turbulence index\n",
            "\u001b[2m\u001b[36m(pid=3867)\u001b[0m Successfully added turbulence index\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=3866)\u001b[0m 2021-07-28 11:35:04,730\tDEBUG rollout_worker.py:1303 -- Creating policy for default_policy\n",
            "\u001b[2m\u001b[36m(pid=3866)\u001b[0m 2021-07-28 11:35:04,731\tDEBUG catalog.py:708 -- Created preprocessor <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7f5d7c3df510>: Box(-inf, inf, (25, 1095), float32) -> (25, 1095)\n",
            "\u001b[2m\u001b[36m(pid=3867)\u001b[0m 2021-07-28 11:35:05,124\tDEBUG rollout_worker.py:1303 -- Creating policy for default_policy\n",
            "\u001b[2m\u001b[36m(pid=3867)\u001b[0m 2021-07-28 11:35:05,126\tDEBUG catalog.py:708 -- Created preprocessor <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7f4430b475d0>: Box(-inf, inf, (25, 1095), float32) -> (25, 1095)\n",
            "\u001b[2m\u001b[36m(pid=3866)\u001b[0m 2021-07-28 11:35:05,289\tINFO torch_policy.py:139 -- TorchPolicy (worker=1) running on CPU.\n",
            "\u001b[2m\u001b[36m(pid=3867)\u001b[0m 2021-07-28 11:35:05,698\tINFO torch_policy.py:139 -- TorchPolicy (worker=2) running on CPU.\n",
            "\u001b[2m\u001b[36m(pid=3866)\u001b[0m 2021-07-28 11:35:05,851\tDEBUG rollout_worker.py:572 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)\n",
            "\u001b[2m\u001b[36m(pid=3866)\u001b[0m 2021-07-28 11:35:05,852\tDEBUG rollout_worker.py:713 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f5d79149e10> (<TradingEnv instance>), policies {'default_policy': <ray.rllib.policy.policy_template.PPOTorchPolicy object at 0x7f5d79683950>}\n",
            "2021-07-28 11:35:05,867\tDEBUG rollout_worker.py:1303 -- Creating policy for default_policy\n",
            "2021-07-28 11:35:05,869\tDEBUG catalog.py:708 -- Created preprocessor <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7fb0c42d7090>: Box(-inf, inf, (25, 1095), float32) -> (25, 1095)\n",
            "\u001b[2m\u001b[36m(pid=3867)\u001b[0m 2021-07-28 11:35:06,282\tDEBUG rollout_worker.py:572 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)\n",
            "\u001b[2m\u001b[36m(pid=3867)\u001b[0m 2021-07-28 11:35:06,283\tDEBUG rollout_worker.py:713 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x7f44410d7310> (<TradingEnv instance>), policies {'default_policy': <ray.rllib.policy.policy_template.PPOTorchPolicy object at 0x7f443df783d0>}\n",
            "2021-07-28 11:35:06,432\tINFO torch_policy.py:139 -- TorchPolicy (worker=local) running on CPU.\n",
            "2021-07-28 11:35:06,785\tINFO rollout_worker.py:1344 -- Built policy map: {'default_policy': <ray.rllib.policy.policy_template.PPOTorchPolicy object at 0x7fb0c42d72d0>}\n",
            "2021-07-28 11:35:06,787\tINFO rollout_worker.py:1345 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7fb0c42d7090>}\n",
            "2021-07-28 11:35:06,792\tDEBUG rollout_worker.py:572 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)\n",
            "2021-07-28 11:35:06,801\tINFO rollout_worker.py:602 -- Built filter map: {'default_policy': MeanStdFilter((25, 1095), True, True, None, (n=0, mean_mean=0.0, mean_std=0.0), (n=0, mean_mean=0.0, mean_std=0.0))}\n",
            "2021-07-28 11:35:06,802\tDEBUG rollout_worker.py:713 -- Created rollout worker with env None (None), policies {'default_policy': <ray.rllib.policy.policy_template.PPOTorchPolicy object at 0x7fb0c42d72d0>}\n",
            "2021-07-28 11:35:06,838\tINFO trainable.py:109 -- Trainable.setup took 381.750 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
            "2021-07-28 11:35:06,849\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
            "2021-07-28 11:35:07,480\tINFO trainable.py:383 -- Restored on 172.28.0.2 from checkpoint: /root/ray_results/PPO/PPO_TradingEnv_f49fd_00000_0_2021-07-28_11-21-29/checkpoint_000001/checkpoint-1\n",
            "2021-07-28 11:35:07,484\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 1, '_timesteps_total': None, '_time_total': 126.85442018508911, '_episodes_total': 1}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uhe6WQqM47Ro"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTMfXA4q38Ft",
        "outputId": "38769c37-6787-4867-d603-6241ec9f554d"
      },
      "source": [
        "def create_eval_env(config): \n",
        "\n",
        "\n",
        "  df = get_data('2020-01-01', '2020-07-27', tickers, tech_indicator_list)\n",
        "\n",
        "  USD.precision = 6\n",
        "  features = []\n",
        "  for key, group in df.groupby('tic'):\n",
        "      for column in group.columns:\n",
        "          if column in {'date','tic'} : \n",
        "              continue\n",
        "          s = Stream.source(group[column].values.tolist(), dtype=float).rename(key+'_'+column)\n",
        "          features.append(s)\n",
        "\n",
        "  feed = DataFeed(features)\n",
        "  feed.compile()\n",
        "\n",
        "  prices = []\n",
        "  for key, group in df.groupby('tic'):\n",
        "      s = Stream.source(group['close'].values.tolist(), dtype=float).rename('USD/' + key)\n",
        "      prices.append(s)\n",
        "\n",
        "  exchange = Exchange(\"alpaca\", service=execute_order)(*prices)\n",
        "\n",
        "  stonks = [Instrument(x, 6, x) for x in tickers]\n",
        "  cash = 2000.\n",
        "  starting_cash = Wallet(exchange, cash * USD )\n",
        "  #initialize no owned stocks\n",
        "  wallets = [starting_cash] + [Wallet(exchange, 0*x) for x in stonks]\n",
        "\n",
        "  portfolio = Portfolio(\n",
        "      base_instrument=USD,\n",
        "      wallets=wallets\n",
        "  )\n",
        "  env = default.create(\n",
        "    feed=feed,\n",
        "    portfolio=portfolio,\n",
        "    action_scheme=\"managed-risk\",\n",
        "    reward_scheme=\"risk-adjusted\",\n",
        "    renderer='matplot',\n",
        "    window_size=25,\n",
        "    max_allowed_loss=0.6\n",
        "  )\n",
        "  return env \n",
        "\n",
        "# Instantiate the environment\n",
        "env = create_env({\n",
        "    \"window_size\": 25\n",
        "})\n",
        "\n",
        "# Run until episode ends\n",
        "episode_reward = 0\n",
        "done = False\n",
        "obs = env.reset()\n",
        "\n",
        "while not done:\n",
        "    action = agent.compute_action(obs)\n",
        "    obs, reward, done, info = env.step(action)\n",
        "    episode_reward += reward\n",
        "\n",
        "env.render()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (249368, 8)\n",
            "Successfully added technical indicators\n",
            "Successfully added turbulence index\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-28 11:54:22,160\tWARNING deprecation.py:34 -- DeprecationWarning: `compute_action` has been deprecated. Use `compute_single_action` instead. This will raise an error in the future!\n",
            "2021-07-28 11:55:22,200\tWARNING deprecation.py:34 -- DeprecationWarning: `compute_action` has been deprecated. Use `compute_single_action` instead. This will raise an error in the future!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7Dr4BO16wER",
        "outputId": "a28814cb-0913-44d6-b01d-f96b581eefa1"
      },
      "source": [
        "env.action_scheme.portfolio.net_worth, env.action_scheme.portfolio.initial_net_worth , env.action_scheme.portfolio.net_worth / env.action_scheme.portfolio.initial_net_worth \n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45791.50228293309, 2000.0, 22.895751141466548)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FB9CzIQX5lVA"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwbnjE6Q7tnY"
      },
      "source": [
        "checkpoint_path = checkpoints[0][0]\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "awyRsjot8I2g",
        "outputId": "4b15e6d8-026d-4c14-c9e2-492442a9b88c"
      },
      "source": [
        "checkpoint_path"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/ray_results/PPO/PPO_TradingEnv_f49fd_00000_0_2021-07-28_11-21-29/checkpoint_000001/checkpoint-1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Tx0qKuK-ReW"
      },
      "source": [
        "agent.s"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}